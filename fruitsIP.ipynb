{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3bf1061-26a2-4411-814c-ba7415d597f0",
   "metadata": {},
   "source": [
    "#### Organizing the data\n",
    "\n",
    "For TensorFlow to correctly assess the data, it needs to be organized like this"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a01bb3a0-1fdc-4c75-bfef-c59a19544bdf",
   "metadata": {},
   "source": [
    "dataset/\n",
    "│\n",
    "├── train/\n",
    "│   ├── class_1/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   ├── image2.jpg\n",
    "│   │   └── ...\n",
    "│   ├── class_2/\n",
    "│   │   ├── image1.jpg\n",
    "│   │   ├── image2.jpg\n",
    "│   │   └── ...\n",
    "│   └── ...\n",
    "│\n",
    "└── test/\n",
    "    ├── class_1/\n",
    "    │   ├── image1.jpg\n",
    "    │   ├── image2.jpg\n",
    "    │   └── ...\n",
    "    ├── class_2/\n",
    "    │   ├── image1.jpg\n",
    "    │   ├── image2.jpg\n",
    "    │   └── ...\n",
    "    └── ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94ad09-c339-4046-b5b9-4e9c303a4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for consolidating the original data set (optional)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Base directory containing Training and Test folders\n",
    "base_dir = r\"fruits-360_dataset_100x100\\fruits-360\"\n",
    "output_dir = r\"consolidated_fruits\"\n",
    "\n",
    "class_mapping = {\n",
    "    \"Apple 6\": \"Apple\",\n",
    "    \"Apple Braeburn 1\": \"Apple\",\n",
    "    \"Apple Crimson Snow 1\": \"Apple\",\n",
    "    \"Apple Golden 1\": \"Apple\",\n",
    "    \"Apple Golden 2\": \"Apple\",\n",
    "    \"Apple Golden 3\": \"Apple\",\n",
    "    \"Apple Granny Smith 1\": \"Apple\",\n",
    "    \"Apple hit 1\": \"Apple\",\n",
    "    \"Apple Pink Lady 1\": \"Apple\",\n",
    "    \"Apple Red 1\": \"Apple\",\n",
    "    \"Apple Red 2\": \"Apple\",\n",
    "    \"Apple Red 3\": \"Apple\",\n",
    "    \"Apple Red Delicious 1\": \"Apple\",\n",
    "    \"Apple Red Yellow 1\": \"Apple\",\n",
    "    \"Apple Red Yellow 2\": \"Apple\",\n",
    "    \"Apricot 1\": \"Apricot\",\n",
    "    \"Avocado 1\": \"Avocado\",\n",
    "    \"Avocado ripe 1\": \"Avocado\",\n",
    "    \"Banana 1\": \"Banana\",\n",
    "    \"Banana Lady Finger 1\": \"Banana\",\n",
    "    \"Banana Red 1\": \"Banana\",\n",
    "    \"Beetroot 1\": \"Beetroot\",\n",
    "    \"Blueberry 1\": \"Blueberry\",\n",
    "    \"Cabbage white 1\": \"Cabbage\",\n",
    "    \"Cactus fruit 1\": \"Cactus fruit\",\n",
    "    \"Cantaloupe 1\": \"Melon\",\n",
    "    \"Cantaloupe 2\": \"Melon\",\n",
    "    \"Carambula 1\": \"Carambula\",\n",
    "    \"Carrot 1\": \"Carrot\",\n",
    "    \"Cauliflower 1\": \"Cauliflower\",\n",
    "    \"Cherry 1\": \"Cherry\",\n",
    "    \"Cherry 2\": \"Cherry\",\n",
    "    \"Cherry Rainier 1\": \"Cherry\",\n",
    "    \"Cherry Wax Black 1\": \"Cherry\",\n",
    "    \"Cherry Wax Red 1\": \"Cherry\",\n",
    "    \"Cherry Wax Yellow 1\": \"Cherry\",\n",
    "    \"Chestnut 1\": \"Chestnut\",\n",
    "    \"Clementine 1\": \"Clementine\",\n",
    "    \"Cocos 1\": \"Cocos\",\n",
    "    \"Corn 1\": \"Corn\",\n",
    "    \"Corn Husk 1\": \"Corn Husk\",\n",
    "    \"Cucumber 1\": \"Cucumber\",\n",
    "    \"Cucumber 3\": \"Cucumber\",\n",
    "    \"Cucumber Ripe 1\": \"Cucumber\",\n",
    "    \"Cucumber Ripe 2\": \"Cucumber\",\n",
    "    \"Dates 1\": \"Dates\",\n",
    "    \"Eggplant 1\": \"Eggplant\",\n",
    "    \"Eggplant long 1\": \"Eggplant\",\n",
    "    \"Fig 1\": \"Fig\",\n",
    "    \"Ginger Root 1\": \"Ginger Root\",\n",
    "    \"Granadilla 1\": \"Granadilla\",\n",
    "    \"Grape Blue 1\": \"Grape\",\n",
    "    \"Grape Pink 1\": \"Grape\",\n",
    "    \"Grape White 1\": \"Grape\",\n",
    "    \"Grape White 2\": \"Grape\",\n",
    "    \"Grape White 3\": \"Grape\",\n",
    "    \"Grape White 4\": \"Grape\",\n",
    "    \"Grapefruit Pink 1\": \"Grapefruit\",\n",
    "    \"Grapefruit White 1\": \"Grapefruit\",\n",
    "    \"Guava 1\": \"Guava\",\n",
    "    \"Hazelnut 1\": \"Hazelnut\",\n",
    "    \"Huckleberry 1\": \"Huckleberry\",\n",
    "    \"Kaki 1\": \"Kaki\",\n",
    "    \"Kiwi 1\": \"Kiwi\",\n",
    "    \"Kohlrabi 1\": \"Kohlrabi\",\n",
    "    \"Kumquats 1\": \"Kumquats\",\n",
    "    \"Lemon 1\": \"Lemon\",\n",
    "    \"Lemon Meyer 1\": \"Lemon\",\n",
    "    \"Limes 1\": \"Limes\",\n",
    "    \"Lychee 1\": \"Lychee\",\n",
    "    \"Mandarine 1\": \"Mandarine\",\n",
    "    \"Mango 1\": \"Mango\",\n",
    "    \"Mango Red 1\": \"Mango\",\n",
    "    \"Mangostan 1\": \"Mangostan\",\n",
    "    \"Maracuja 1\": \"Maracuja\",\n",
    "    \"Melon Piel de Sapo 1\": \"Melon\",\n",
    "    \"Mulberry 1\": \"Mulberry\",\n",
    "    \"Nectarine 1\": \"Nectarine\",\n",
    "    \"Nectarine Flat 1\": \"Nectarine\",\n",
    "    \"Nut Forest 1\": \"Nut Fores\",\n",
    "    \"Nut Pecan 1\": \"Nut Pecan\",\n",
    "    \"Onion Red 1\": \"Onion\",\n",
    "    \"Onion Red Peeled 1\": \"Onion\",\n",
    "    \"Onion White 1\": \"Onion\",\n",
    "    \"Orange 1\": \"Orange\",\n",
    "    \"Papaya 1\": \"Papaya\",\n",
    "    \"Passion Fruit 1\": \"Passion Fruit\",\n",
    "    \"Peach 1\": \"Peach\",\n",
    "    \"Peach 2\": \"Peach\",\n",
    "    \"Peach Flat 1\": \"Peach\",\n",
    "    \"Pear 1\": \"Pear\",\n",
    "    \"Pear 2\": \"Pear\",\n",
    "    \"Pear 3\": \"Pear 3\",\n",
    "    \"Pear Abate 1\": \"Pear\",\n",
    "    \"Pear Forelle 1\": \"Pear\",\n",
    "    \"Pear Kaiser 1\": \"Pear\",\n",
    "    \"Pear Monster 1\": \"Pear\",\n",
    "    \"Pear Red 1\": \"Pear\",\n",
    "    \"Pear Stone 1\": \"Pear\",\n",
    "    \"Pear Williams 1\": \"Pear\",\n",
    "    \"Pepino 1\": \"Pepino\",\n",
    "    \"Pepper Green 1\": \"Pepper\",\n",
    "    \"Pepper Orange 1\": \"Pepper\",\n",
    "    \"Pepper Red 1\": \"Pepper\",\n",
    "    \"Pepper Yellow 1\": \"Pepper\",\n",
    "    \"Physalis 1\": \"Physalis\",\n",
    "    \"Physalis with Husk 1\": \"Physalis\",\n",
    "    \"Pineapple 1\": \"Pineapple\",\n",
    "    \"Pineapple Mini 1\": \"Pineapple\",\n",
    "    \"Pitahaya Red 1\": \"Pitahaya\",\n",
    "    \"Plum 1\": \"Plum\",\n",
    "    \"Plum 2\": \"Plum\",\n",
    "    \"Plum 3\": \"Plum\",\n",
    "    \"Pomegranate 1\": \"Pomegranate\",\n",
    "    \"Pomelo Sweetie 1\": \"Pomelo Sweetie\",\n",
    "    \"Potato Red 1\": \"Potato\",\n",
    "    \"Potato Red Washed 1\": \"Potato\",\n",
    "    \"Potato Sweet 1\": \"Potato\",\n",
    "    \"Potato White 1\": \"Potato\",\n",
    "    \"Quince 1\": \"Quince\",\n",
    "    \"Rambutan 1\": \"Rambutan\",\n",
    "    \"Raspberry 1\": \"Raspberry\",\n",
    "    \"Redcurrant 1\": \"Redcurrant\",\n",
    "    \"Salak 1\": \"Salak\",\n",
    "    \"Strawberry 1\": \"Strawberry\",\n",
    "    \"Strawberry Wedge 1\": \"Strawberry\",\n",
    "    \"Tamarillo 1\": \"Tamarillo\",\n",
    "    \"Tangelo 1\": \"Tangelo\",\n",
    "    \"Tomato 1\": \"Tomato\",\n",
    "    \"Tomato 2\": \"Tomato\",\n",
    "    \"Tomato 3\": \"Tomato\",\n",
    "    \"Tomato 4\": \"Tomato\",\n",
    "    \"Tomato Cherry Red 1\": \"Tomato\",\n",
    "    \"Tomato Heart 1\": \"Tomato\",\n",
    "    \"Tomato Maroon 1\": \"Tomato\",\n",
    "    \"Tomato not Ripened 1\": \"Tomato\",\n",
    "    \"Tomato Yellow 1\": \"Tomato\",\n",
    "    \"Walnut 1\": \"Walnut\",\n",
    "    \"Watermelon 1\": \"Melon\",\n",
    "    \"Zucchini 1\": \"Zucchini\",\n",
    "    \"Zucchini dark 1\": \"Zucchini\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Process each subfolder (Training and Test)\n",
    "for subfolder in [\"Training\", \"Test\"]:\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        print(f\"Subfolder '{subfolder}' not found in '{base_dir}'. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Target folder for consolidated data\n",
    "    output_subfolder = os.path.join(output_dir, subfolder)\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "    # Iterate through class folders in the subfolder\n",
    "    for class_folder in os.listdir(subfolder_path):\n",
    "        class_folder_path = os.path.join(subfolder_path, class_folder)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Determine the consolidated class name\n",
    "        target_class = class_mapping.get(class_folder, class_folder)  # Keep original name if not mapped\n",
    "        target_folder = os.path.join(output_subfolder, target_class)\n",
    "\n",
    "        # Ensure the target class folder exists\n",
    "        os.makedirs(target_folder, exist_ok=True)\n",
    "        \n",
    "        print(f\"{class_folder} -> {target_class}\")\n",
    "\n",
    "        # Move images to the consolidated folder\n",
    "        for image_name in os.listdir(class_folder_path):\n",
    "            src_image_path = os.path.join(class_folder_path, image_name)\n",
    "\n",
    "            # Add the original class name to the image filename to avoid overlap\n",
    "            new_image_name = f\"{class_folder}_{image_name}\"\n",
    "            dst_image_path = os.path.join(target_folder, new_image_name)\n",
    "\n",
    "            # Copy the image to the target folder with the new name\n",
    "            shutil.copy(src_image_path, dst_image_path)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Dataset has been reorganized. Consolidated dataset is saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bb3f9-c615-41cd-9771-567cd7552201",
   "metadata": {},
   "source": [
    "## Training the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a9d7e-53d4-4d4b-b520-765b330119f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"fruits-360_dataset_100x100\\fruits-360\\Training\"\n",
    "test_dir = r\"fruits-360_dataset_100x100\\fruits-360\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585b2fc-2e2c-4b05-8cef-7be42a14992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data Generator\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(100, 100),                        \n",
    "    batch_size=32, \n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e6660-869a-47ea-9a96-c805275cec1b",
   "metadata": {},
   "source": [
    "We will be using a pretrained model, MobileNetV2, as a base for our model. Since our dataset is relatively small and generalizable, this will be easier and more optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453331f5-77ca-4e19-924e-01dca296e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained Model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "\n",
    "# Freeze base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classifier\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(train_data.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9139a9-95fa-404e-99bb-e12d4e3dd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "model.fit(train_data, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963702fa-a8d6-4cd2-b6bc-daffaa276293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in HDF5 format\n",
    "model.save('my_model_notuning.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2689101-f51c-4857-adfa-d0a542da5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the HDF5 file\n",
    "loaded_model = load_model('my_model.keras')\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada95483-9f70-4a37-be8f-432c20567150",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba031c-4913-4eaf-a9cf-240e65e4cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6732ac-378a-4b3c-bef8-f7e0a5370128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(model.history.history['accuracy'], label='Training Accuracy')  # Correct reference\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(model.history.history['loss'], label='Training Loss')  # Correct reference\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plots to a PDF\n",
    "plt.savefig('training_charts.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cca21-692a-4be0-9860-8b650584b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09272304-a641-4f61-83dc-89237e6f6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Generate predictions for the test data\n",
    "test_data.reset()\n",
    "y_pred = model.predict(test_data)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = test_data.classes\n",
    "class_labels = list(test_data.class_indices.keys())\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred_classes, target_names=class_labels, output_dict=True)\n",
    "\n",
    "# Convert the report to a DataFrame for easier manipulation\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Extract F1 scores\n",
    "f1_scores = report_df['f1-score'].iloc[:-3]  # Exclude 'accuracy', 'macro avg', and 'weighted avg'\n",
    "\n",
    "# Plot F1 scores\n",
    "plt.figure(figsize=(16, 8))\n",
    "f1_scores.plot(kind='bar', color='skyblue')\n",
    "plt.title('F1 Scores for Each Class')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF\n",
    "plt.savefig('f1_scores_bar_chart.pdf')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805bbcdf-1d50-49ee-bc54-44ef5d856c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores.to_csv('f1_scores.csv', header=['F1 Score'])\n",
    "\n",
    "with open('f1_scores.txt', 'w') as file:\n",
    "    for class_name, score in f1_scores.items():\n",
    "        file.write(f\"{class_name}: {score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998107c4-ca9e-42aa-a206-c8029eddd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate support directly from y_true\n",
    "class_labels = list(test_data.class_indices.keys())\n",
    "unique, counts = np.unique(y_true, return_counts=True)\n",
    "support_dict = dict(zip(unique, counts))\n",
    "support = [support_dict[i] for i in range(len(class_labels))]\n",
    "\n",
    "# Plot support as a bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(class_labels, support, color='lightcoral', alpha=0.7)\n",
    "plt.title('Class Support (Number of Samples)', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Support (Number of Samples)', fontsize=14)\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PDF\n",
    "plt.savefig('class_support.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c1cff4-5493-489e-bd10-067fba43d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a sample image\n",
    "img_path = r\"Project-D6-FruitIP-main\\Project-D6-FruitIP-main\\realfruits100x100\\real_apple1.jpg\"\n",
    "img = image.load_img(img_path, target_size=(100, 100))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "predicted_label = test_data.class_indices.keys()\n",
    "\n",
    "# Display the image with the predicted label\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {list(predicted_label)[predicted_class]}\")\n",
    "plt.axis('off')\n",
    "plt.savefig('example_prediction.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40596a-6e40-40c1-a3f4-d50bcd05d62d",
   "metadata": {},
   "source": [
    "## Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739fa9d-2ef9-4017-b0ac-3ddf4f218430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Load Pretrained Model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "\n",
    "# Freeze base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Unfreeze last 50 layers in base_model for fine-tuning\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(train_data.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),  # Lower learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Pass class weights during training\n",
    "model.fit(train_data, epochs=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
